{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AEoS: Adaptive Edge of Stability (Cohen et al. arXiv:2207.14484v2)\n",
    "\n",
    "Reproduce key CIFAR-10 FC plots: λ_H, λ_A, λ_lim(η,β1) = (2+2β1)/((1-β1)η) = 38/η for β1=0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Plots are saved to `plots/*.png` for GitHub rendering; interactive HTML versions are saved to `plots/html/*.html`. Plots are also displayed interactively in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub-safe Plotly rendering setup\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install kaleido if missing (safe in-notebook install)\n",
    "try:\n",
    "    import kaleido\n",
    "    KALEIDO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Installing kaleido for static image generation...\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"kaleido\", \"--quiet\", \"--user\"])\n",
    "        import kaleido\n",
    "        KALEIDO_AVAILABLE = True\n",
    "        print(\"✓ kaleido installed successfully\")\n",
    "    except Exception as e:\n",
    "        KALEIDO_AVAILABLE = False\n",
    "        print(f\"⚠ Warning: Could not install kaleido: {e}\")\n",
    "        print(\"  Plots will be saved as HTML only (no PNG)\")\n",
    "\n",
    "def show_github(fig, name, out_dir=\"plots\", html_dir=\"plots/html\", width=1200, height=700, scale=2):\n",
    "    \"\"\"\n",
    "    Save Plotly figure as PNG and HTML for GitHub rendering, and display interactively.\n",
    "    \n",
    "    Args:\n",
    "        fig: Plotly figure object\n",
    "        name: Descriptive filename (without extension)\n",
    "        out_dir: Output directory for PNGs (default: \"plots\")\n",
    "        html_dir: Output directory for HTML files (default: \"plots/html\")\n",
    "        width: Image width in pixels\n",
    "        height: Image height in pixels\n",
    "        scale: Image scale factor for higher resolution\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the saved PNG file (or HTML if PNG failed)\n",
    "    \"\"\"\n",
    "    # Create output directories if they don't exist\n",
    "    out_path = Path(out_dir)\n",
    "    out_path.mkdir(exist_ok=True)\n",
    "    html_path_dir = Path(html_dir)\n",
    "    html_path_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Sanitize filename (replace spaces with _, remove weird chars)\n",
    "    safe_name = re.sub(r'[^\\w\\-_\\.]', '_', str(name))\n",
    "    safe_name = re.sub(r'_+', '_', safe_name)  # Replace multiple underscores with single\n",
    "    safe_name = safe_name.strip('_')  # Remove leading/trailing underscores\n",
    "    \n",
    "    # Ensure figure has dimensions\n",
    "    if not hasattr(fig.layout, 'width') or fig.layout.width is None:\n",
    "        fig.update_layout(width=width, height=height)\n",
    "    \n",
    "    png_path = out_path / f\"{safe_name}.png\"\n",
    "    html_path = html_path_dir / f\"{safe_name}.html\"\n",
    "    \n",
    "    png_saved = False\n",
    "    \n",
    "    # Try to save PNG (if kaleido available)\n",
    "    if KALEIDO_AVAILABLE:\n",
    "        try:\n",
    "            fig.write_image(str(png_path), width=width, height=height, scale=scale)\n",
    "            # Display PNG inline for GitHub\n",
    "            display(Image(str(png_path)))\n",
    "            print(f\"✓ Saved PNG: {png_path}\")\n",
    "            png_saved = True\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Warning: Could not save PNG ({e}), saving HTML only\")\n",
    "    else:\n",
    "        print(\"⚠ Warning: kaleido not available, saving HTML only\")\n",
    "    \n",
    "    # Always save HTML for interactive viewing (in separate folder)\n",
    "    try:\n",
    "        fig.write_html(str(html_path))\n",
    "        print(f\"✓ Saved HTML: {html_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error saving HTML: {e}\")\n",
    "    \n",
    "    # Display interactively in Jupyter (like fig.show())\n",
    "    fig.show()\n",
    "    \n",
    "    return str(png_path) if png_saved else str(html_path)\n",
    "\n",
    "print(\"✓ GitHub-safe Plotly rendering configured\")\n",
    "print(f\"  Plots will be saved to: {Path('plots').absolute()}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: Test GitHub rendering\n",
    "test_fig = go.Figure(data=go.Scatter(x=[1, 2, 3, 4], y=[10, 11, 12, 13], mode='lines+markers'))\n",
    "test_fig.update_layout(title=\"GitHub Render Test\", xaxis_title=\"X\", yaxis_title=\"Y\")\n",
    "test_path = show_github(test_fig, \"github_render_test\")\n",
    "print(f\"Test plot saved to: {test_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub-safe Plotly rendering setup\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install kaleido if missing (safe in-notebook install)\n",
    "try:\n",
    "    import kaleido\n",
    "    KALEIDO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Installing kaleido for static image generation...\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"kaleido\", \"--quiet\", \"--user\"])\n",
    "        import kaleido\n",
    "        KALEIDO_AVAILABLE = True\n",
    "        print(\"✓ kaleido installed successfully\")\n",
    "    except Exception as e:\n",
    "        KALEIDO_AVAILABLE = False\n",
    "        print(f\"⚠ Warning: Could not install kaleido: {e}\")\n",
    "        print(\"  Plots will be saved as HTML only (no PNG)\")\n",
    "\n",
    "def show_github(fig, name, out_dir=\"plots\", width=1200, height=700, scale=2):\n",
    "    \"\"\"\n",
    "    Save Plotly figure as PNG and HTML for GitHub rendering.\n",
    "    \n",
    "    Args:\n",
    "        fig: Plotly figure object\n",
    "        name: Descriptive filename (without extension)\n",
    "        out_dir: Output directory (default: \"plots\")\n",
    "        width: Image width in pixels\n",
    "        height: Image height in pixels\n",
    "        scale: Image scale factor for higher resolution\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the saved PNG file\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    out_path = Path(out_dir)\n",
    "    out_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Sanitize filename (replace spaces with _, remove weird chars)\n",
    "    safe_name = re.sub(r'[^\\w\\-_\\.]', '_', str(name))\n",
    "    safe_name = re.sub(r'_+', '_', safe_name)  # Replace multiple underscores with single\n",
    "    safe_name = safe_name.strip('_')  # Remove leading/trailing underscores\n",
    "    \n",
    "    # Ensure figure has dimensions\n",
    "    if not hasattr(fig.layout, 'width') or fig.layout.width is None:\n",
    "        fig.update_layout(width=width, height=height)\n",
    "    \n",
    "    png_path = out_path / f\"{safe_name}.png\"\n",
    "    html_path = out_path / f\"{safe_name}.html\"\n",
    "    \n",
    "    # Try to save PNG (if kaleido available)\n",
    "    if KALEIDO_AVAILABLE:\n",
    "        try:\n",
    "            fig.write_image(str(png_path), width=width, height=height, scale=scale)\n",
    "            # Display PNG inline for GitHub\n",
    "            display(Image(str(png_path)))\n",
    "            print(f\"✓ Saved PNG: {png_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Warning: Could not save PNG ({e}), saving HTML only\")\n",
    "            KALEIDO_AVAILABLE_FOR_THIS = False\n",
    "    else:\n",
    "        print(\"⚠ Warning: kaleido not available, saving HTML only\")\n",
    "        KALEIDO_AVAILABLE_FOR_THIS = False\n",
    "    \n",
    "    # Always save HTML for interactive viewing\n",
    "    try:\n",
    "        fig.write_html(str(html_path))\n",
    "        if not KALEIDO_AVAILABLE or not KALEIDO_AVAILABLE_FOR_THIS:\n",
    "            print(f\"✓ Saved HTML: {html_path} (use this for interactive viewing)\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error saving HTML: {e}\")\n",
    "    \n",
    "    return str(png_path) if KALEIDO_AVAILABLE and KALEIDO_AVAILABLE_FOR_THIS else str(html_path)\n",
    "\n",
    "print(\"✓ GitHub-safe Plotly rendering configured\")\n",
    "print(f\"  Plots will be saved to: {Path('plots').absolute()}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path(\"..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import src.seed as seed\n",
    "import src.models as models\n",
    "import src.functions as fn\n",
    "import src.aeos as aeos\n",
    "\n",
    "device = seed.device\n",
    "generator = torch.Generator(device=device).manual_seed(seed.SEED)\n",
    "DATA_DIR = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##(launch-scipy-ml.sh -W DSC180A_FA25_A00 -c 4 -m 16 -g 1 -v a30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_full_batch(use_full=True):\n",
    "    \"\"\"Load CIFAR-10. use_full=True -> 50k train, 10k test (paper repro).\"\"\"\n",
    "    X, y, X_test, y_test = fn.load_cifar_10(use_full=use_full)\n",
    "    return X, y, X_test, y_test\n",
    "\n",
    "# Paper repro: full CIFAR-10 (50k/10k). One step = one full pass (grad accumulation if needed).\n",
    "PAPER_REPRO = True\n",
    "X, y, X_test, y_test = load_cifar10_full_batch(use_full=PAPER_REPRO)\n",
    "BATCH_SIZE = 5000  # grad accumulation; set >= len(X) for true full-batch in one forward\n",
    "print(f\"Train: {X.shape[0]}, Test: {X_test.shape[0]}, batch_size={BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpness: HVP, Power Iteration, λ_H, λ_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_iteration_top_eigenvalue(matvec, dim, iters=20, seed_val=42):\n",
    "    gen = torch.Generator(device=device).manual_seed(seed_val)\n",
    "    v = torch.randn(dim, device=device, generator=gen)\n",
    "    v = v / v.norm()\n",
    "    for _ in range(iters):\n",
    "        Hv = matvec(v)\n",
    "        v = Hv / (Hv.norm() + 1e-12)\n",
    "    lam = v.dot(matvec(v)).item()\n",
    "    return lam\n",
    "\n",
    "def lambda_lim(eta, beta1):\n",
    "    return (2 + 2 * beta1) / ((1 - beta1) * eta)\n",
    "\n",
    "def compute_lambda_H(model, criterion, params, X, y, batch_size, iters=20):\n",
    "    \"\"\"Top eigenvalue of H. params = single ordering (optimizer.param_groups[0]['params']).\"\"\"\n",
    "    model.eval()\n",
    "    dim = sum(p.numel() for p in params)\n",
    "    def matvec(v):\n",
    "        _, _, Hv = aeos.full_batch_loss_grad_hvp(model, criterion, params, X, y, v, batch_size)\n",
    "        return Hv\n",
    "    lam = power_iteration_top_eigenvalue(matvec, dim, iters=iters)\n",
    "    model.train()\n",
    "    return lam\n",
    "\n",
    "def compute_lambda_A(model, optimizer, criterion, params, X, y, bias_correction, batch_size, iters=20):\n",
    "    \"\"\"Top eigenvalue of P^{-1/2} H P^{-1/2}. P = diag(sqrt(v)+eps), v = raw exp_avg_sq if no BC.\"\"\"\n",
    "    inv_sqrt_p = aeos.get_P_inv_sqrt_from_optimizer(optimizer, params, bias_correction)\n",
    "    if inv_sqrt_p is None:\n",
    "        return float(\"nan\")\n",
    "    model.eval()\n",
    "    dim = inv_sqrt_p.numel()\n",
    "    def matvec(v):\n",
    "        u = inv_sqrt_p * v\n",
    "        _, _, Hu = aeos.full_batch_loss_grad_hvp(model, criterion, params, X, y, u, batch_size)\n",
    "        return inv_sqrt_p * Hu\n",
    "    lam = power_iteration_top_eigenvalue(matvec, dim, iters=iters)\n",
    "    model.train()\n",
    "    return lam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Adam (no bias correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(model, lr, beta1, beta2, eps, bias_correction=True):\n",
    "    params = list(model.parameters())\n",
    "    if bias_correction:\n",
    "        return torch.optim.Adam(params, lr=lr, betas=(beta1, beta2), eps=eps)\n",
    "    return aeos.AdamNoBiasCorrection(params, lr=lr, betas=(beta1, beta2), eps=eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop and caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_V2 = Path(\"../output/eos/adam_PP_v2_full\")\n",
    "OUTPUT_V2.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def run_experiment(\n",
    "    run_name, lr, beta1, beta2=0.999, eps=1e-7, steps=500, bias_correction=False,\n",
    "    sharpness_every=5, power_iters=20, force_rerun=False, batch_size=None\n",
    "):\n",
    "    batch_size = batch_size if batch_size is not None else BATCH_SIZE\n",
    "    run_dir = OUTPUT_V2 / run_name\n",
    "    meta_path = run_dir / \"metadata.json\"\n",
    "    metrics_path = run_dir / \"metrics.csv\"\n",
    "    if not force_rerun and meta_path.exists() and metrics_path.exists():\n",
    "        with open(meta_path) as f:\n",
    "            meta = json.load(f)\n",
    "        df = pd.read_csv(metrics_path)\n",
    "        return meta, df\n",
    "\n",
    "    torch.manual_seed(seed.SEED)\n",
    "    model = models.PaperFCNet(input_size=3072, num_labels=10).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = make_optimizer(model, lr, beta1, beta2, eps, bias_correction)\n",
    "    params = list(optimizer.param_groups[0][\"params\"])\n",
    "\n",
    "    try:\n",
    "        from tqdm.auto import tqdm\n",
    "        step_iter = tqdm(range(steps), desc=run_name, unit=\"step\")\n",
    "    except ImportError:\n",
    "        step_iter = range(steps)\n",
    "    lim = lambda_lim(lr, beta1)\n",
    "    rows = []\n",
    "    print_interval = max(1, steps // 20)\n",
    "    for step in step_iter:\n",
    "        loss_val = aeos.full_batch_grad_step(model, criterion, optimizer, X, y, params, batch_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(X)\n",
    "            train_acc = (out.argmax(1) == y).float().mean().item()\n",
    "            test_out = model(X_test)\n",
    "            test_acc = (test_out.argmax(1) == y_test).float().mean().item()\n",
    "            grads = [p.grad for p in params if p.grad is not None]\n",
    "            gnorm = torch.cat([g.reshape(-1) for g in grads]).norm().item() if grads else 0.0\n",
    "\n",
    "        lam_H = lam_A = float(\"nan\")\n",
    "        if step % sharpness_every == 0:\n",
    "            lam_H = compute_lambda_H(model, criterion, params, X, y, batch_size, iters=power_iters)\n",
    "            lam_A = compute_lambda_A(model, optimizer, criterion, params, X, y, bias_correction, batch_size, iters=power_iters)\n",
    "\n",
    "        rows.append({\n",
    "            \"step\": step, \"train_loss\": loss_val, \"train_acc\": train_acc, \"test_acc\": test_acc,\n",
    "            \"lambda_H\": lam_H, \"lambda_A\": lam_A, \"grad_norm\": gnorm\n",
    "        })\n",
    "        if (step + 1) % print_interval == 0 or (step + 1) == steps:\n",
    "            lam_str = f\", λ_A={lam_A:.2f}\" if (lam_A == lam_A) else \"\"\n",
    "            if hasattr(step_iter, \"set_postfix\"):\n",
    "                pf = {\"loss\": f\"{loss_val:.4f}\"}\n",
    "                if lam_A == lam_A:\n",
    "                    pf[\"λ_A\"] = f\"{lam_A:.1f}\"\n",
    "                step_iter.set_postfix(**pf)\n",
    "            else:\n",
    "                print(f\"  step {step+1}/{steps}, loss={loss_val:.4f}{lam_str}\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    meta = {\"lr\": lr, \"beta1\": beta1, \"beta2\": beta2, \"eps\": eps, \"bias_correction\": bias_correction,\n",
    "            \"steps\": steps, \"seed\": seed.SEED, \"sharpness_every\": sharpness_every, \"model_arch\": \"PaperFCNet_5x200_tanh\", \"batch_size\": batch_size}\n",
    "    with open(meta_path, \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "    df.to_csv(metrics_path, index=False)\n",
    "    return meta, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity run (50 steps, 1 LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sanity run: 50 steps, lr=1e-4, sharpness_every=10\")\n",
    "meta_s, df_s = run_experiment(\"sanity\", lr=1e-4, beta1=0.9, steps=50, sharpness_every=10, force_rerun=True)\n",
    "lim_s = lambda_lim(1e-4, 0.9)\n",
    "valid = df_s[\"lambda_A\"].dropna()\n",
    "if len(valid) > 0:\n",
    "    er = valid / lim_s\n",
    "    print(f\"edge_ratio: median={er.median():.3f}, IQR=[{er.quantile(0.25):.3f}, {er.quantile(0.75):.3f}]\")\n",
    "    print(f\"λ_lim(1e-4, 0.9) = {lim_s:.1f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 1(a): vary η\n",
    "\n",
    "To run experiments from the terminal (e.g. overnight): `python run_aeos_full.py` or `python run_aeos_full.py --quick` for a shorter run. The notebook loads from cache if files exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs_fig1a = [3e-5, 1e-4, 3.2e-4, 1e-3]\n",
    "for eta in lrs_fig1a:\n",
    "    run_experiment(f\"fig1a_eta_{eta}\", lr=eta, beta1=0.9, beta2=0.999, eps=1e-7, steps=500, sharpness_every=5)\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, subplot_titles=(\"Train loss vs step\", \"λ_A vs step (log)\"), shared_xaxes=True)\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\"]\n",
    "for i, eta in enumerate(lrs_fig1a):\n",
    "    try:\n",
    "        df = pd.read_csv(OUTPUT_V2 / f\"fig1a_eta_{eta}\" / \"metrics.csv\")\n",
    "        d = df.dropna(subset=[\"lambda_A\"])\n",
    "        fig.add_trace(go.Scatter(x=df[\"step\"], y=df[\"train_loss\"], name=f\"η={eta}\", line=dict(color=colors[i])), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=d[\"step\"], y=d[\"lambda_A\"], name=f\"η={eta}\", line=dict(color=colors[i]), yaxis=\"y2\"), row=2, col=1)\n",
    "        lim = lambda_lim(eta, 0.9)\n",
    "        fig.add_hline(y=lim, line_dash=\"dash\", line_color=colors[i], opacity=0.7, row=2, col=1)\n",
    "    except Exception as e:\n",
    "        print(f\"Skip {eta}: {e}\")\n",
    "fig.update_yaxes(type=\"log\", row=2, col=1)\n",
    "fig.update_layout(height=500, title=\"Fig 1(a)-style: vary η\")\n",
    "show_github(fig, \"fig1a_vary_eta\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 1(b): vary β1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_fig1b = [0.64, 0.814, 0.903, 0.95]\n",
    "for b1 in betas_fig1b:\n",
    "    run_experiment(f\"fig1b_beta1_{b1}\", lr=1e-4, beta1=b1, beta2=0.999, eps=1e-7, steps=500, sharpness_every=5)\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, subplot_titles=(\"Train loss vs step\", \"λ_A vs step (log)\"), shared_xaxes=True)\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\"]\n",
    "for i, b1 in enumerate(betas_fig1b):\n",
    "    try:\n",
    "        df = pd.read_csv(OUTPUT_V2 / f\"fig1b_beta1_{b1}\" / \"metrics.csv\")\n",
    "        d = df.dropna(subset=[\"lambda_A\"])\n",
    "        fig.add_trace(go.Scatter(x=df[\"step\"], y=df[\"train_loss\"], name=f\"β1={b1}\", line=dict(color=colors[i])), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=d[\"step\"], y=d[\"lambda_A\"], name=f\"β1={b1}\", line=dict(color=colors[i]), yaxis=\"y2\"), row=2, col=1)\n",
    "        lim = lambda_lim(1e-4, b1)\n",
    "        fig.add_hline(y=lim, line_dash=\"dash\", line_color=colors[i], opacity=0.7, row=2, col=1)\n",
    "    except Exception as e:\n",
    "        print(f\"Skip β1={b1}: {e}\")\n",
    "fig.update_yaxes(type=\"log\", row=2, col=1)\n",
    "fig.update_layout(height=500, title=\"Fig 1(b)-style: vary β1\")\n",
    "show_github(fig, \"fig1b_vary_beta1\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 8: λ_A flatlines, λ_H keeps rising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs_fig8 = [5e-5, 1e-4, 2e-4, 4e-4]\n",
    "for eta in lrs_fig8:\n",
    "    run_experiment(f\"fig8_eta_{eta}\", lr=eta, beta1=0.9, beta2=0.99, eps=1e-7, steps=1000, sharpness_every=5)\n",
    "\n",
    "fig = make_subplots(rows=3, cols=1, subplot_titles=(\"Train loss\", \"λ_A (log)\", \"λ_H (log)\"), shared_xaxes=True, vertical_spacing=0.08)\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\"]\n",
    "for i, eta in enumerate(lrs_fig8):\n",
    "    try:\n",
    "        df = pd.read_csv(OUTPUT_V2 / f\"fig8_eta_{eta}\" / \"metrics.csv\")\n",
    "        fig.add_trace(go.Scatter(x=df[\"step\"], y=df[\"train_loss\"], name=f\"η={eta}\", line=dict(color=colors[i])), row=1, col=1)\n",
    "        d = df.dropna(subset=[\"lambda_A\"])\n",
    "        fig.add_trace(go.Scatter(x=d[\"step\"], y=d[\"lambda_A\"], name=f\"η={eta}\", line=dict(color=colors[i])), row=2, col=1)\n",
    "        fig.add_hline(y=lambda_lim(eta, 0.9), line_dash=\"dash\", line_color=colors[i], opacity=0.7, row=2, col=1)\n",
    "        dH = df.dropna(subset=[\"lambda_H\"])\n",
    "        fig.add_trace(go.Scatter(x=dH[\"step\"], y=dH[\"lambda_H\"], name=f\"η={eta}\", line=dict(color=colors[i])), row=3, col=1)\n",
    "    except Exception as e:\n",
    "        print(f\"Skip {eta}: {e}\")\n",
    "fig.update_yaxes(type=\"log\", row=2, col=1)\n",
    "fig.update_yaxes(type=\"log\", row=3, col=1)\n",
    "fig.update_layout(height=700, title=\"Fig 8-style: λ_A flatlines, λ_H rises\")\n",
    "show_github(fig, \"fig8_lambda_A_H\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-run dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_run_dashboard(run_name):\n",
    "    df = pd.read_csv(OUTPUT_V2 / run_name / \"metrics.csv\")\n",
    "    with open(OUTPUT_V2 / run_name / \"metadata.json\") as f:\n",
    "        meta = json.load(f)\n",
    "    lr, b1 = meta[\"lr\"], meta[\"beta1\"]\n",
    "    lim = lambda_lim(lr, b1)\n",
    "    fig = make_subplots(rows=2, cols=1, specs=[[{\"secondary_y\": True}], [{}]],\n",
    "                        subplot_titles=(\"Loss, λ_H, λ_A\", \"Test accuracy\"), shared_xaxes=True)\n",
    "    fig.add_trace(go.Scatter(x=df[\"step\"], y=df[\"train_loss\"], name=\"train loss\"), row=1, col=1, secondary_y=False)\n",
    "    d = df.dropna(subset=[\"lambda_H\"])\n",
    "    fig.add_trace(go.Scatter(x=d[\"step\"], y=d[\"lambda_H\"], name=\"λ_H\"), row=1, col=1, secondary_y=True)\n",
    "    dA = df.dropna(subset=[\"lambda_A\"])\n",
    "    fig.add_trace(go.Scatter(x=dA[\"step\"], y=dA[\"lambda_A\"], name=\"λ_A\"), row=1, col=1, secondary_y=True)\n",
    "    fig.add_hline(y=lim, line_dash=\"dash\", annotation_text=\"λ_lim\", row=1, col=1, secondary_y=True)\n",
    "    fig.add_trace(go.Scatter(x=df[\"step\"], y=df[\"test_acc\"], name=\"test acc\"), row=2, col=1)\n",
    "    fig.update_layout(height=450, title=f\"Dashboard: {run_name}\")\n",
    "    fig.update_yaxes(title_text=\"loss\", row=1, col=1, secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"sharpness\", type=\"log\", row=1, col=1, secondary_y=True)\n",
    "    return fig\n",
    "\n",
    "show_github(plot_single_run_dashboard(\"sanity\"), \"single_run_dashboard_sanity\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation: edge_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_ratio(t) = λ_A(t)/λ_lim over time (paper: expect ~1)\n",
    "lrs_fig1a = [3e-5, 1e-4, 3.2e-4, 1e-3]\n",
    "betas_fig1b = [0.64, 0.814, 0.903, 0.95]\n",
    "lrs_fig8 = [5e-5, 1e-4, 2e-4, 4e-4]\n",
    "runs = [\"sanity\"] + [f\"fig1a_eta_{e}\" for e in lrs_fig1a] + [f\"fig1b_beta1_{b}\" for b in betas_fig1b] + [f\"fig8_eta_{e}\" for e in lrs_fig8]\n",
    "fig_er = go.Figure()\n",
    "for r in runs:\n",
    "    if not (OUTPUT_V2 / r / \"metrics.csv\").exists():\n",
    "        continue\n",
    "    df = pd.read_csv(OUTPUT_V2 / r / \"metrics.csv\")\n",
    "    with open(OUTPUT_V2 / r / \"metadata.json\") as f:\n",
    "        meta = json.load(f)\n",
    "    lim = lambda_lim(meta[\"lr\"], meta[\"beta1\"])\n",
    "    d = df.dropna(subset=[\"lambda_A\"]).copy()\n",
    "    d[\"edge_ratio\"] = d[\"lambda_A\"] / lim\n",
    "    fig_er.add_trace(go.Scatter(x=d[\"step\"], y=d[\"edge_ratio\"], name=r, mode=\"lines+markers\"))\n",
    "fig_er.add_hline(y=1.0, line_dash=\"dash\", annotation_text=\"λ_lim\")\n",
    "fig_er.update_layout(title=\"edge_ratio(t) = λ_A/λ_lim\", xaxis_title=\"step\", yaxis_title=\"edge_ratio\", height=400)\n",
    "show_github(fig_er, \"edge_ratio_vs_step\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_edge_ratio_validation(run_name):\n",
    "    df = pd.read_csv(OUTPUT_V2 / run_name / \"metrics.csv\")\n",
    "    with open(OUTPUT_V2 / run_name / \"metadata.json\") as f:\n",
    "        meta = json.load(f)\n",
    "    lr, b1 = meta[\"lr\"], meta[\"beta1\"]\n",
    "    lim = lambda_lim(lr, b1)\n",
    "    valid = df[\"lambda_A\"].dropna()\n",
    "    if len(valid) == 0:\n",
    "        print(f\"{run_name}: no λ_A\")\n",
    "        return\n",
    "    last_20 = valid.iloc[-max(1, len(valid)//5):]\n",
    "    er = last_20 / lim\n",
    "    print(f\"{run_name}: last_20%_median={er.median():.3f}, IQR=[{er.quantile(0.25):.3f}, {er.quantile(0.75):.3f}] (expect ~1)\")\n",
    "\n",
    "lrs_fig1a = [3e-5, 1e-4, 3.2e-4, 1e-3]\n",
    "betas_fig1b = [0.64, 0.814, 0.903, 0.95]\n",
    "lrs_fig8 = [5e-5, 1e-4, 2e-4, 4e-4]\n",
    "for r in [\"sanity\"] + [f\"fig1a_eta_{e}\" for e in lrs_fig1a] + [f\"fig1b_beta1_{b}\" for b in betas_fig1b] + [f\"fig8_eta_{e}\" for e in lrs_fig8]:\n",
    "    if (OUTPUT_V2 / r / \"metrics.csv\").exists():\n",
    "        print_edge_ratio_validation(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
